## ğŸ”´ Limitation 1: **High Memory & Computation Cost**

### ğŸ“Œ What it means:
- KDE needs to **store and compare all training features** when estimating densities.
- In deep feature space, this becomes a **huge amount of data**, especially with high-res images and deeper layers of CNNs.

### ğŸ§  Why itâ€™s a problem:
- It gets **slow and memory-hungry**, especially with large datasets.
- Hard to scale to **real-time systems** or **edge devices** (like factory-line cameras).

### ğŸ”§ Example:
Imagine you train on 5,000 high-res images using ResNet50.  
Each feature map might be 2048-dimensions â€” thatâ€™s a ton of data!  
When a test image comes in, it has to compare its features to **all 5,000 samples**, which is **slow**.

---

## ğŸ”´ Limitation 2: **Curse of Dimensionality**

### ğŸ“Œ What it means:
- KDE struggles in **high-dimensional spaces** â€” this is called the â€œcurse of dimensionalityâ€.
- As dimensions go up, data becomes sparse, and **density estimates become unreliable**.

### ğŸ§  Why itâ€™s a problem:
- Deep features from CNNs are often very high-dimensional.
- KDE may say, â€œthis is rare,â€ not because itâ€™s truly rare, but because **density estimation is poor** in that dimension.

### ğŸ”§ Example:
Suppose a slightly brighter image of a normal screw creates a feature vector that lies on the edge of the KDE model.  
Even though itâ€™s just **a lighting change**, KDE might wrongly flag it as anomalous because the high-dimensional estimate is **not smooth or accurate**.

---

## ğŸ”´ Limitation 3: **Sensitivity to Feature Choice**

### ğŸ“Œ What it means:
- DFKDE's output heavily depends on **which CNN** and **which layer** you extract features from.
- Different CNNs and layers capture **different types of patterns** (textures, shapes, etc.).

### ğŸ§  Why itâ€™s a problem:
- Thereâ€™s no one-size-fits-all layer â€” poor layer choice = bad detection.
- It needs **careful tuning** and might not generalize well between datasets.

### ğŸ”§ Example:
Say you use a shallow CNN layer that focuses on textures â€” it might miss shape anomalies.  
Or you use a very deep layer â€” it may ignore low-level texture defects like **surface cracks**, and **fail to detect real damage**.

---

## ğŸ”´ Limitation 4: **Local Variations or Noise Can Mislead the Model**

### ğŸ“Œ What it means:
- KDE sees *any deviation* from the normal distribution as a potential anomaly â€” even **harmless variations** like lighting, shadow, or camera blur.

### ğŸ§  Why itâ€™s a problem:
- Model may raise **false alarms** for images that are **technically normal**, but differ slightly due to noise or conditions.

### ğŸ”§ Example:
Imagine two perfectly normal screws â€” one under bright light, one under dim light.  
The lighting causes their features to shift slightly.  
KDE might say the dim one is anomalous just because it looks **less like the training distribution**.

---

## ğŸ”´ Limitation 5: **No Localization of Anomalies**

### ğŸ“Œ What it means:
- DFKDE gives you a **score** for the whole image, but **doesnâ€™t tell you where** the anomaly is.

### ğŸ§  Why itâ€™s a problem:
- In real-world applications (e.g., manufacturing or medical imaging), you often need to **pinpoint the defect**, not just know it exists.

### ğŸ”§ Example:
You get a score of 0.91 anomaly probability for a toothbrush.  
But whereâ€™s the problem? The handle? The bristles? Background?  
DFKDE canâ€™t tell â€” youâ€™ll need **another method** to localize it.